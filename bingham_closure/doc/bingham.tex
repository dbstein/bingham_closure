\documentclass{article}
\usepackage{amsmath,amssymb}
\usepackage{breqn}
\usepackage{graphicx}
\usepackage[left=1in,right=1in,top=1in,bottom=1in]{geometry}
\usepackage{cleveref}

\makeatletter
\newcommand*{\declarecommand}{%
  \@star@or@long\declare@command
}
\newcommand*{\declare@command}[1]{%
  \provide@command{#1}{}%
  \renew@command{#1}%
}
\makeatother

\declarecommand{\x}{{\mathbf{x}}}
\declarecommand{\p}{{\mathbf{p}}}

\declarecommand{\u}{{\mathbf{u}}}
\declarecommand{\U}{{\mathbf{U}}}
\declarecommand{\grad}{\nabla}
\declarecommand{\Wi}{\textnormal{Wi}}
\declarecommand{\Id}{\mathbb{I}}
\declarecommand{\f}{{\mathbf{f}}}
\declarecommand{\F}{{\mathbf{F}}}
\declarecommand{\n}{{\mathbf{n}}}
\declarecommand{\X}{{\mathbf{X}}}
\declarecommand{\b}{{\mathbf{b}}}
\declarecommand{\a}{{\mathbf{a}}}
\declarecommand{\bmu}{{\boldsymbol{\mu}}}
\declarecommand{\tS}{{\tilde S}}

\begin{document}

\section{The Bingham closure}

The Bingham closure is given by:
\begin{equation}
    S(\x) = \int\psi_B(\x,\p)\p\p\p\p\,d\p,
\end{equation}
where the Bingham distribution $\psi_B(\x,\p)$ is defined by the constraints that:
\begin{subequations}
    \begin{align}
        \int\psi_B(\x,\p)\,d\p      &= \phi(x),  \\
        \int\psi_B(\x,\p)\p\p\,d\p  &= D(\x),
    \end{align}
\end{subequations}
where $\phi$ and $D$ are the zeroth and second moments with respect to the true distribution function $\psi$. We assume that $\psi_B(\x,\p)$ takes the form:
\begin{align}
    \psi_B(\x,\p) = Ae^{B:\p\p}.
\end{align}
Given $\phi(\x)$ and $D(\x)$, our goals is to find the coefficients $A$ and $B$. Because $B$ only appears contracted against a symmetric matrix, it is sufficient to assume that $B$ is symmetric. In fact, we will see that our goal is even simpler than this: we will only be interested in computing $S:E$ and $S:D$, where $E=\grad\u+\grad\u^\intercal$. The purpose of this package is to provide optimized routines for computing these contractions. This documentation describes how the package works.

\section{The Bingham Closure in 2D}

\subsection{A simple formula for the closure}

From Chaubal and Leal, $B$ and $D$ are diagonalized in the same frame. We assume that we are in this frame; and compute the closure here. We will clean up details afterwards. In this frame, we have that:
\begin{subequations}
    \begin{align}
        1 &= \int_0^{2\pi}Ae^{\lambda_0\cos^2\theta + \lambda_1\sin^2\theta}\,d\theta,   \\
        \mu_0 &= \int_0^{2\pi}Ae^{\lambda_0\cos^2\theta + \lambda_1\sin^2\theta}\cos^2\theta\,d\theta,   \\
        \mu_1 &= \int_0^{2\pi}Ae^{\lambda_0\cos^2\theta + \lambda_1\sin^2\theta}\sin^2\theta\,d\theta,
    \end{align}
\end{subequations}
Note we have assumed here that $\phi=1$. $\mu$ and $\lambda$ are the eigenvalues of $D$ and $B$ respectively, with $\mu_0>\mu_1$. We note that $\lambda$ can only be fixed up to an additive constant: to see this, let $\lambda_0$ and $\lambda_1$ solve the above equations.  Then letting $\tilde\lambda_i=\lambda_i+C$ for $i=0,1$, we have:
\begin{equation}
    \int_0^{2\pi}Ae^{\tilde\lambda_0\cos^2\theta + \tilde\lambda_0\sin^2\theta}f(\theta)\,d\theta = \int_0^{2\pi}Ae^{C}e^{\lambda_0\cos^2\theta + \lambda_1\sin^2\theta}f(\theta)\,d\theta,
\end{equation}
which simply changes the definition of $A$. We can choose a convenient choice of $C$ then; it is convenient to choose $C$ so that $\lambda_0 + \lambda_1 = 0$. Then we have that:
\begin{subequations}
    \begin{align}
        1 &= \int_0^{2\pi}Ae^{\lambda_0(\cos^2\theta - \sin^2\theta)}\,d\theta,   \\
        \mu_0 &= \int_0^{2\pi}Ae^{\lambda_0(\cos^2\theta - \sin^2\theta)}\cos^2\theta\,d\theta.
    \end{align}
\end{subequations}
Exploiting the trig identity that $\cos^2\theta-\sin^2\theta=\cos(2\theta)$, and because:
\begin{equation}
    \int_0^{2\pi}e^{\lambda_0\cos(2\theta)}\,d\theta = 2\pi I_0(\lambda_0),
\end{equation}
we find that
\begin{equation}
    A = \frac{1}{2\pi I_0(\lambda_0)},
\end{equation}
where $I_v$ is the modified Bessel function of the first kind. Thus we find:
Now we're down to the single equation:
\begin{equation}
    \mu_0 = \frac{1}{2\pi I_0(\lambda_0)}\int_0^{2\pi}e^{\lambda_0\cos(2\theta)}\cos^2\theta\,d\theta.
\end{equation}
Evaluating this final integral and simplifying gives:
\begin{equation}
    2\mu_0 = 1 + \zeta(\lambda_0),
\end{equation}
where we have defined $\zeta(x)=I_1(x)/I_0(x)$. Thus to find $\lambda_0$ given $\mu_0$, we simply need to solve this nonlinear equation for $\lambda_0$.

\subsection{Solution of the closure equation and numerical issues}

In this section we consider the issues with solving the nonlinear equation:
\begin{equation}
    2\mu = 1 + \zeta(\lambda)
    \label{eqn:bingham_nonlinear}
\end{equation}
for $\lambda$, given $\mu\in[0.5,1.0]$. Note that $\mu_0$, the largest eigenvalue, must live in this range becuase it is the largest eigenvalue and the eigenvalues sum to $1$. The fundamental problem with simply throwing a naive Newton solver at this equation is that as $\mu\to1$, $\lambda\to\infty$. While not a problem in and of itself, $\zeta(\lambda)$ is the ratio of $I_1(\lambda)$ and $I_0(\lambda)$. Both of these functions diverge exponentially fast as $\lambda$ gets large, and so naive evaluation of the ratio fails. Nevertheless, their ratio converges to $1$: our primary challenge is to find a way to evaluate $\zeta$ stably for large arguments. Fortunately, we are in luck! As it turns out, we can write:
\begin{equation}
    I_\nu(z) = \frac{e^z}{\sqrt{2\pi z}}\mathcal{P}_\nu(z),
\end{equation}
where $\mathcal{P}_\nu(z)$ is a power series in $z^{-1}$ that converges for sufficiently large $z$. Our strategy is clear, then. For small arguments, we can evaluate $\zeta$ directly. For larger arguments, we compute $\zeta$ by:
\begin{equation}
    \zeta(\lambda) = \mathcal{P}_1(\lambda)/\mathcal{P}_0(\lambda).
\end{equation}
In my numerical experiments, the power series $\mathcal{P}_0$ and $\mathcal{P}_1$ converge rapidly when the argument is at least $20$, and direct evaluation has no issues for this size argument. We thus evaluate $\zeta$ directly for $|\lambda|\leq20$, and indirectly via the power series representations for $|\lambda|>20$.

In order to find $\lambda$, we compute the solution to the equation $1/2 + \zeta(\lambda)/2 - \mu = 0$. The Jacobian is given by:
\begin{equation}
    2\mathcal{J}(\lambda) = 1 - \zeta(\lambda)/\lambda - \zeta(\lambda)^2.
\end{equation}
Fortunately, the singularity in $\zeta(\lambda)/\lambda$ is removable. We construct a function to evaluate this quantity using the function\_generator package, on an approximation interval of $[ -1.001, 1.0]$. These bounds are chosen so that evaluation points for the Chebyshev interpolants used by the function\_generator do not live at the singularity. When $|\lambda|>1$, we evaluate this quantity direclty.

\subsection{Fast evaluation of the closure equation}

This provides a stable way to compute $\lambda(\mu)$ for every value of $\mu\in[0.5, 1.0]$, but it requires a Newton iteration for every value of $\mu$ given. Instead, we might consider constructing an interpolant for this function. Unfortunately as mentioned before, as $\mu\to1$, $\lambda\to\infty$. Because the function\_generator package allows for adaptive, brute force interpolation, it could probably handle this. But we can be smarter. Note that what we actually want to calculate is:
\begin{equation}
    S(\x) = \psi_B(\x,\p)\p\p\p\p\,d\p.
\end{equation}
By exploiting identities, as we will show momentarily, we can reduce computing all of this to computing:
\begin{equation}
    S_{0000}(\x) = \int_0^{2\pi}Ae^{\lambda(\x)\cos(2\theta)}\cos^4\theta\,d\theta.
\end{equation}
Again, this function can be computed analytically, and dropping the $\x$, the result is:
\begin{equation}
    S_{0000} = \frac{1}{2} - \frac{\zeta(\lambda)}{4\lambda} + \frac{\zeta(\lambda)}{2}
    \label{eqn:bingham_integral}
\end{equation}
Now we're getting somewhere: we just define the function $S_{0000}(\mu)$ as:
\begin{itemize}
    \item Given, $\mu$, solve \Cref{eqn:bingham_nonlinear} for $\lambda$ using a Newton iteration,
    \item Evaluate \Cref{eqn:bingham_integral} with the argument $\lambda$ from the first step.
\end{itemize}
Fortunately, $S_{0000}(\mu)$ is a bounded and relatively smooth function of $\mu$. Thus we can use function\_generator to construct a nearly machine-precision and very accurate approximation of $S_{0000}(\mu)$.

\section{The full algorithm}

We now assume that we are given $D(\x)$ and outline a method for computing $(S:E)(\x)$ and $(S:D)(\x)$. Because these computations are done pointwise, we will omit $\x$ for the remainder. We first compute the eigendecomposition of $D$:
\begin{equation}
    D = \Omega\Lambda\Omega^\intercal.
\end{equation}
Since $D$ is symmetric positive-definite, we may apply the routine np.linalg.eigh (which is faster than np.linalg.eig) in order to find the ordered eigenvalues. We call $\mu_0$ the larger eigenvalue, and $\mu_1$ the smaller eigenvalue. Using the methodology from above, we compute $\tilde S_{0000}(\mu_0)$. Note that here it is denoted explicitly as $\tilde S_{0000}$ - this is because this is not actually $S_{0000}$, but that value in the diagonalized frame. Via identites, we may compute some of the other components as:
\begin{align}
    \tilde S_{0011} &= \mu_0 - S_{0000},    \\
    \tilde S_{1111} &= \mu_1 - S_{0011},    \\
    \tilde S_{0001} &= 0, \\
    \tilde S_{0111} &= 0,
\end{align}
We now simply have to perform a rotation:
\begin{equation}
    S_{ijkl} = \Omega_{im}\Omega_{jn}\Omega_{kq}\Omega_{lp}\tilde S_{mnqp},
\end{equation}
to get $S$ back. Calculuating this sum is somewhat nasty. Luckily we can exploit symmetries/identites to speed things up:
\begin{align}
    S_{0000} &= \Omega_{00}^4\tilde S_{0000} + 4\Omega_{00}^3\Omega_{01}\tilde S_{0001} + 6\Omega_{00}^2\Omega_{01}^2\tilde S_{0011} + 4\Omega_{00}\Omega_{01}^3\tilde S_{0111} + \Omega_{01}^4 S_{1111},  \\
    S_{0001} &= \Omega_{00}^3\Omega_{10}\tilde S_{0000} + (3\Omega^2\Omega_{01}\Omega_{10} + \Omega_{00}^3\Omega_{11})\tilde S_{0001} + 3(\Omega_{00}\Omega_{01}^2\Omega_{10} + \Omega_{00}^2\Omega_{01}\Omega_{11})\tilde S_{0011} +   \\
        &\qquad(3\Omega_{00}\Omega_{01}^2+\Omega_{11}+\Omega_{01}^3\Omega_{10})\tilde S_{0111} + \Omega_{01}^3\Omega_{11}\tilde S_{1111}.
\end{align}
Note that $\tilde S_{0001}=\tilde S_{0111}=0$, and so these terms can be left out of the sums in implementation, reducing these rotations to:
\begin{align}
    S_{0000} &= \Omega_{00}^4\tilde S_{0000} + 6\Omega_{00}^2\Omega_{01}^2\tilde S_{0011} + \Omega_{01}^4 S_{1111},  \\
    S_{0001} &= \Omega_{00}^3\Omega_{10}\tilde S_{0000} + 3(\Omega_{00}\Omega_{01}^2\Omega_{10} + \Omega_{00}^2\Omega_{01}\Omega_{11})\tilde S_{0011} + \Omega_{01}^3\Omega_{11}\tilde S_{1111}.
\end{align}
Knowing these, we can exploit more identites to find the rest of the components:
\begin{subequations}
    \begin{align}
        S_{0000} + S_{0011} &= D_{00},  \\
        S_{0100} + S_{0111} &= D_{01},  \\
        S_{1100} + S_{1111} &= D_{11}.
    \end{align}
\end{subequations}
Finally now that we have these components of $S$, we just need to compute $S:E$ and $S:D$. For a general symmetric tensor $T$, we have that:
\begin{subequations}
    \begin{align}
        (S:T)_{00} &= S_{0000}T_{00} + S_{0011}T_{11} + 2S_{0001}T_{01},    \\
        (S:T)_{01} &= S_{0001}T_{00} + S_{0111}T_{11} + 2S_{0011}T_{01},    \\
        (S:T)_{11} &= S_{0011}T_{00} + S_{1111}T_{11} + 2S_{0111}T_{01}.
    \end{align}
\end{subequations}
Since $S:T$ is symmetric, $(S:T)_{10}=(S:T)_{01}$.

\end{document}
